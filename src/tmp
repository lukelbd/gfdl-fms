#!/usr/bin/env bash
usage='drycore_run [OPTION...] DIR'
doc="This script runs the GFDL dry core model in blocks of N days, and processes
the parallel output NetCDF files with './process' before merging them. This means
pressure level interpolation, heat flux calcualtion, etc. are done in parallel
just like the model integration, which can save huge amounts of time. For a
description of namelist/diagnostic table parameters, see README.md.

Usage

  $usage

Positional arguments

  DIR  The directory in which model will be run. Must have 'input.nml' and
       'diag_table' files in the top level.

Run mode spec

  This is the experiment mode. Passed with the flag [-m|--mode]=MODE

  * 0 is control run, the default.
  * 1 is radiation off spindown.
  * 2 is radiation off but surface on spindown.
  * 3 is everything off (radiation, surface, and friction) spindown.
  * 4 for friction off spindown.

Optional arguments

  -h|--help                Print this message.
  -n|--new                 Exit if experiment folder already exists.
  -f|--fix                 Exit if model already ran successfully for full integration time. Use this to restart crashed runs with smaller timestep.
  -r|--resume              Exit if particular run block already exists. Use this to continue interrupted runs.
  -s|--slow                Slow timestep for spinup to minimize crash risk.
  -i|--init)               Exit after saving the 'forcing.nc' forcing data.
  [-c|--cores]=*           The number of cores to parallelize over.
  [-ts|--tstart]=*         The initial day. Can use this to continue from another run.
  [-te|--tend]=*           The final day.
  [-rd|--restart]=*        The initial restart directory.
  [-dn|--days-nodata]=*    Comma-separated list of days for which no data is saved.
  [-ds|--days-spindown]=*  Comma-separated list of initial spindown days.
  [-dxyz|--days-xyzdata]=* Comma-separated list of days for which full res data is saved.
"
# Error function
raise() {
  echo "Usage: $usage" 1>&2
  echo "Error: $@" 1>&2
  exit 1
}
# Function for reading values set in namelist
nml_parse() {
  [ ! -r "$cwd/input.nml" ]  && raise "input.nml file not found."
  cat input.nml | sed 's/!.*//g' | grep "$1" | cut -d= -f2 | tr -d "\t ,'\""
}

################################################################################
# Check input
################################################################################
# Declare defaults and parse input
cores=4
tstart=0
newexp=false
resume=false
days=$(nml_parse days) # number of days in each block
while [ $# -gt 0 ]; do # echo "Flag: $1"
  case "$1" in
    -h|--help) echo "$doc" && exit 0  ;;
    -n|--new)          newexp=true    ;;
    -r|--resume)       resume=true    ;;
    -c=*|--cores=*)    cores=${1#*=}  ;;
    -ts=*|--start=*)   tstart=${1#*=} ;;
    -te=*|--end=*)     tend=${1#*=}   ;;
    -rd=*|--restart=*) rinit=${1#*=}  ;;
    -*) raise "Unknown flag \"$1\"." ;;
    *)  [ -n "$expdir" ] && raise "More than one experiment directory specified."
      expdir="$1" ;;
  esac; shift # shift by at least one
done
[ -z $expdir ] && raise "You must declare the experiment directory."
[ -z $tend ] && raise "You must declare the end day."
# Check that exe is available
# You should copy the exe from whichever compile script
fms=$cwd/fms.x                   # model executable
mppnccombine=$cwd/mppnccombine.x # netcdf combine executable
! [ -x $fms ]  && raise "The executable $fms is missing."
! [ -x $mppnccombine ] && raise "The executable $mppnccombine is missing."
# Exit from script if directory already exists
$newexp && [ -d $expdir ] && raise "Working directory already exists."
=======
# Initial stuff
ulimit -s unlimited # set max open files
cwd=$(pwd)
cores=8
mode=0
new=false
resume=false
init=false
fix=false
slow=false
slowdays=300 # number of days for slow run
tstart=0 # defaults
tend=0

# Executables
# export MPI_SHEPHERD=true # see: https://www2.cisl.ucar.edu/sites/default/files/intro_to_hpc.pdf
# when mpiexec_mpt used, MPI_SHEPHERD required, but this failed for me
# Make sure module load impi has been declared by parent
run=mpirun # for running in parallel
fms=$HOME/gfdl-drycore/run/fms.x
process=$cwd/process_inline
interp=$cwd/pressure_interp.ncl
! [ -x $fms ]     && raise "The executable $fms is missing."
! [ -x $process ] && raise "The bash script for processing data is missing."
! which $run &>/dev/null && raise "$run not found in \$PATH."

# Parse input flags
# Read the comments to see explanations for each option
while [ $# -gt 0 ]; do # echo "Flag: $1"
  case "$1" in
    -h|--help) echo "$doc" && exit 0 ;;
    -n|--new)  new=true ;; # use this to *exit* if experiment folder already exists
    -f|--fix)  fix=true ;;
    -s|--slow) slow=true ;; # slow start to prevent crash (TODO: maybe delete this)
    -i|--init) init=true ;; # *only* save forcing scheme data to file?
    -r|--resume) resume=true ;; # use this to *autodetect* last day of existing run, continue from there
    -m=*|--mode=*)  mode=${1#*=} ;; # 0 is control, 1 is spindown, 2...
    -c=*|--cores=*) cores=${1#*=} ;;
    -ts=*|--tstart=*)  tstart=${1#*=} ;; # use this to continue from *particular* day of existing run
    -te=*|--tend=*)    tend=${1#*=} ;; # ending day
    -rd=*|--restart=*) rinit=${1#*=} ;; # manual override restart directory
    -dn=*|--days-nodata=*)    t_nodata=($(echo ${1#*=}   | tr ',' ' ')) ;;
    -ds=*|--days-spindown=*)  t_spindown=($(echo ${1#*=} | tr ',' ' ')) ;;
    -dxyz=*|--days-xyzdata=*) t_xyzdata=($(echo ${1#*=}  | tr ',' ' ')) ;;
    -*) pflags+="$1 " ;; # send all extra flags to process function
    *) [ -n "$expdir" ] && raise "More than one experiment directory specified."
       expdir="$1" ;;
  esac
  shift
done
# Warnings and errors
[ -z $expdir ] && raise "You must declare the experiment directory."
! $init && [ $tstart -eq 0 ] && [ $tend -eq 0 ] && raise "Start and end times both zero."
# Use final day
if [ -n "$rinit" ] && ! [[ $rinit =~ d.*-d.* ]]; then
  rinit=($rinit/d*-d*);
  rinit="${rinit[-1]}"
  echo "Warning: Using final block ${rinit##*/} for restart files."
fi
# Messages
[ ${#t_nodata[@]} -gt 0 ]    && echo "Removing all data for days: ${t_nodata[@]}."
[ ${#t_xyzdata[@]} -gt 0 ]   && echo "Preserving full resolution for days: ${t_xyzdata[@]}."
[[ $mode -ne 0 && ${#t_spindown[@]} -gt 0 ]] && echo "Starting spindown for days: ${t_spindown[@]}"

# Optionally exit from script if directory already exists
$new && [ -d $expdir ] && raise "Working directory already exists. Continuing..."
>>>>>>> /home/ldavis/timescales-exps/drycore_run
if ! [ -d $expdir ]; then
  mkdir $expdir # make directory
  [ $? -ne 0 ] && raise "Could not create experiment directory \"$expdir\"."
fi

<<<<<<< run/run
################################################################################
# Helper functions for model runs
################################################################################
# Set up input files for model executable to read
# by matching indentation, which can be done with <<-DELIM; literal tab chars ignored
# https://unix.stackexchange.com/questions/76481/cant-indent-heredoc-to-match-nestings-indent
################################################################################
# Takes two arguments: 1) the working directory, and 2) the iteration mode
dir_setup() {
  # Set up working directory, and move there
  # Action depends on settings
  wdir="$1" # where to move files
  [ $# -ne 1 ] && raise "dir_setup() functions requires exactly 1 argument."
  if ! [ -d $wdir ]; then
    # Directory does not exist, just create if from scratch
    resume=false
    echo "Setting up working directory ${wdir##*/}..."
  elif $resume; then
    # Directory exists
    # Check if this directory contains finished results
    if ! [ -z "$(\ls $wdir/RESTART 2>/dev/null)" ]; then # need to check RESTART folder is non-empty
      echo "Working directory ${wdir##*/} contains completed integration. Cancelling..."
      return 1
    fi
    # If not, we are "resuming" the experiment run at this timestep
    resume=false
    echo "Working directory ${wdir##*/} contains unfinished integration. Starting over..."
    rm -rf $wdir
  else
    # Delete the folder, we don't care what's in it
    echo "Working directory ${wdir##*/} already exists. Deleting..."
    rm -rf $wdir
  fi
  # Make directory and move stuff over
  mkdir $wdir
  [ $? -ne 0 ] && raise "Could not create working directory \"$wdir\"."
  cd $wdir
  cp $fms ./fms.x   # move executable inside (declared at top of file)
  mkdir RESTART     # model spits out stuff here, can be accepted as input to new iteration
  mkdir INPUT       # model reads from this
  touch field_table # just put empty file, if want no tracers
  # Copy files over
  ! [ -r "$cwd/input.nml" ]  && raise "input.nml file not found."
  ! [ -r "$cwd/diag_table" ] && raise "diag_table file not found."
  cat $cwd/input.nml | sed 's/!.*//g' | sed 's/[ \t]*$//g' | sed $'/^[ \t]*$/d' >./input.nml
  cp $cwd/diag_table ./
  topo=$(nml_parse topography_option) # use helper function
  if [ "$topo" == "input" ]; then
    ! [ -r $cwd/topography.data.nc ] && raise "Topography file not found"
    cp $cwd/topography.data.nc INPUT
  fi
  return 0
}

################################################################################
# Function for restarting model; put correct files in correct place so 
# fms can read them and continue iteration from a previous state.
################################################################################
# Take one argument: directory where restart files exist
copy_restart() {
  # Move restart files
  local rdir=$1 # the restart direcotry
  [ $# -ne 1 ] && raise "copy_restart() function takes exactly 1 argument."
  if ! [ -d "$rdir" ] || ! [ -d "$rdir/RESTART" ] || [ -z "$(ls $rdir/RESTART/*.nc 2>/dev/null)" ] || ! [ -r "$rdir/RESTART/atmos_model.res" ]; then
    raise "Restart directory $rdir/RESTART does not exist, or is empty."
  fi
  echo "Moving restart files from ${rdir##*/}/RESTART to ${PWD##*/}/INPUT..."
  for file in $rdir/RESTART/*; do
    cp $file INPUT/${file##*/}
  done
=======
# Usage is array_in value ${array[@]}, behaves like python 'value in array'
array_in() {
  [[ " ${@:2} " =~ " ${1} " ]]
  return $?
}
# Get namelist value for the *global*, experiment-series namelist
nml_parse() {
  cat $expdir/input.nml | sed 's/!.*//g' | grep "$1" | cut -d= -f2 | xargs | sed 's/,$//g'
}
# Replace namelist value for a *local* spindown experiment
nml_replace() { # first argument is param name, second argument is value
  while [ $# -gt 0 ]; do
    ! grep '^[ \t]*\b'"${1}"'\b' ./input.nml &>/dev/null && \
      raise "Param \"${1}\" not found in namelist."
    space='\([ \t]*\)' # space atom; more readable to set it as a variable
    echo "Replacing \"${1}\" with ${2}."
    sed -i 's/^'"${space}${1}${space}"'='"${space}"'.*$/\1'"${1}"'\2=\3'"${2}"',/g' ./input.nml
    shift 2
    [ $? -ne 0 ] && raise "Must pass even number of params to nml_replace function."
  done
}
days=$(nml_parse days) # number of days in each block
# Process exit status
exit_check() {
  estatus=$1
  if [ $estatus != 0 ]; then
    echo "Exit status $estatus from post-processing previous block..." 1>&2
    case $estatus in
      1) raise "NetCDF files missing. Check log.model." ;;
      2) raise "Something failed during plev or isen interpolation. Check log.process." ;;
      3) raise "Something failed while getting plev zonal means. Check log.process." ;;
      4) raise "Something failed while getting plev or isen params. Check log.process." ;;
      *) raise "Check log.process; other/miscellaneous failure." ;;
    esac
  fi
}
# NCL status
ncl_check() { # input log file as argument
  cat $1 | grep -v "Execute.c" | grep -v "systemfunc" | grep -E "^fatal:" &>/dev/null
}

################################################################################
# Function for restarting model; put correct files in correct place so 
# fms can read them and continue iteration from a previous state.
################################################################################
# Take one argument: directory where restart files exist
copy_restart() {
  # Move restart files
  local cday rdir
  cday=$1
  rdir=$2 # the restart direcotry
  [ $# -ne 2 ] && raise "copy_restart() function takes exactly 2 arguments."
  if ! [ -d "$rdir" ] || ! [ -d "$rdir/RESTART" ] || [ -z "$(ls $rdir/RESTART/*.nc 2>/dev/null)" ] || ! [ -r "$rdir/RESTART/atmos_model.res" ]; then
    raise "Restart directory $rdir/RESTART does not exist, or is empty."
  fi
  echo "Moving restart files from ${rdir##*/}/RESTART to ${PWD##*/}/INPUT..."
  for file in $rdir/RESTART/*; do
    cp $file INPUT/${file##*/}
  done
  # Enforce starting time
  # WARNING: After day 10000, 'days' field runs into 'month' field in atmos_model.res
  # which causes weird error with 1 timestep in output NetCDF files and data corruption
  # Editing namelist does not work because current time overwritten by the
  # INPUT/atmos_model.res file. Need to edit the latter.
  if [ $cday -eq 0 ]; then
    sed -i 's/ \+/ /g;s/[0-9]*[1-9][0-9]*/0/g' INPUT/atmos_model.res
    cp $rdir/input.nml ../restart.nml # store the restart namelist in root directory for experiment
    echo ${rdir} >../restart.log
  fi
}

################################################################################
# Set up input files for model executable to read
# Takes two arguments: 1) the working directory, and 2) the iteration mode
################################################################################
dir_setup() {
  # Set up working directory, and move there
  local cday wdir
  cday="$1"
  wdir="$2" # where to move files
  [ $# -ne 2 ] && raise "dir_setup() function takes exactly 2 arguments."
  if ! [ -d $wdir ]; then
    # Resume run here
    echo "Setting up working directory ${wdir##*/}..."
    fix=false
    resume=false
  elif $fix; then
    # Restart failed run from *beginning*, suitable for when run is unstable
    # and we are trying a smaller timestep
    # TODO: Do not hardcode final experiment day
    expect=5500
    days=($wdir/../d????-d????)
    days=(${days[@]##*d})
    if [ ${days[-1]} == $expect ]; then
      echo "Model run already completed."
      return 1
    fi
    # Go
    echo "Restarting experiment."
    fix=false
    resume=false
    rm -rf $wdir
  elif $resume; then
    # Resume interrupted run
    # NOTE: This checks for contents of netcdf folder
    if compgen -G "$wdir/../netcdf/*${wdir##*/}.nc" &>/dev/null; then
      echo "NetCDF files already exist for block ${wdir##*/}. Cancelling..."
      return 1 # breaks out of if statement
    fi
    # Otherwise, resume run and delete 'unfinished' contents
    echo "No NetCDF files found for block ${wdir##*/}. Resuming..."
    resume=false
    rm -rf $wdir
  else
    # Overwrite
    echo "Working directory ${wdir##*/} already exists. Deleting..."
    rm -rf $wdir
  fi

  # Make directory and move stuff over
  mkdir $wdir
  [ $? -ne 0 ] && raise "Failed to create working directory \"$wdir\"." && return 1
  cd $wdir
  cp $fms ./fms.x # move executable inside (declared at top of file)
  mkdir RESTART # model spits out stuff here, can be accepted as input to new iteration
  mkdir INPUT   # model reads from this
  touch field_table # just put empty file, if want no tracers

  # Copy existing namelist file over
  # For shutdown experiments, can edit on the fly to turn off
  # radiation, et cetera, but this is starting point
  ! [ -r $expdir/input.nml ]  && raise "input.nml file not found."
  ! [ -r $expdir/diag_table ] && raise "diag_table file not found."
  cp $expdir/input.nml  ./
  cp $expdir/diag_table ./
  topo=$(nml_parse "topography_option") # use helper function
  if [ "$topo" == "input" ]; then
    ! [ -r $expdir/topography.data.nc ] && raise "Topography file not available."
    cp $expdir/topography.data.nc ./
  fi

  # Namelist changes for spindown runs
  if [ $mode -gt 0 ]; then
    case $mode in   # determine spindown type
      1) nml_replace ktrop 0 kbl 0 kstrat 0 kmeso 0 ;; # turn off all thermal damping
      2) nml_replace ktrop 0 kstrat 0 kmeso 0 ;; # turn off damping except in boundary layer
      3) nml_replace ktrop 0 kfric 0 kbl 0 kstrat 0 kmeso 0 ;; # turn off all damping
      4) nml_replace kfric 0 ;; # turn off friction
      *) raise "Unknown experiment identifier \"$mode\"." ;;
    esac
  fi
  # Namelist changes to compensate for initial instability with strong mean
  # damping and weak eddy damping
  # if $slow && [ $cday -eq 0 ]; then # slow start for mean damping experiments, to get mean state to
  if $slow && [ $cday -lt $slowdays ]; then # next 300 days, eddies grow
    echo "Fixing initial model instability."
    for param in ktrop kstrat kmeso kbl; do
      k=$(nml_parse $param | cut -d, -f1) # use mean damping rate
      nml_replace $param "$k, $k" # apply mean damping rate to both
    done
  fi
  # Parent script will test return code; ensure zero here
  return 0
>>>>>>> /home/ldavis/timescales-exps/drycore_run
}

################################################################################
# Function for running the next model step from a previous step
<<<<<<< run/run
################################################################################
run_model() {
  local rdir=$1 # the restart direcotry
  [ $# -ne 1 ] && raise "run_model() function takes exactly 1 argument."
  t=$(date +%s)
  echo "Running model..."
  # Use mpirun to run model in parallel (note mpirun must be on path)
  ! which mpirun &>/dev/null && raise "mpirun not found in \$PATH: ${PATH}."
  mpirun -np $cores ./fms.x &>log.model # need ./fms.x, not fms
  # Check that model ran successfully
  # FMS prints to standard output 'EXIT CODE: 1' but doesn't actually set
  # the exit status/mpirun doesn't pass that exit status, which is dumb. So we'll parse the logfile.
  grep 'EXIT CODE: [1-9]' log.model &>/dev/null && raise "Bad exit code from model run step."
  echo "Time for integration: $(($(date +%s) - $t))s."
  # Combine the parallel-output netcdf files with the GFDL-provided 'mppnccombine' tool (stands for massively parallel processing netcdf-combine)
  t=$(date +%s)
  for ncfile in *.nc.0000; do # for each output filename -- e.g. 4xdaily_inst.nc.XXXX, averages.nc.XXXX, etc.
    # Get list of files to combine
    [[ "$ncfile" =~ "*" ]] && raise "No netcdf files found."
    files=(${ncfile%%.*}.nc*) # glob expands into "bash array" of files; the %%.* is a "parameter expansion" (google this)
    # Combine files
    echo "Combining files: ${files[@]} into ${ncfile%%.*}.nc"
    $mppnccombine -r ${ncfile%%.*}.nc ${files[@]} # -r flag says to remove the decomposed .0000 files after they are combined
    [ $? -ne 0 ] && raise "mppnccombine failed."
    mv ${ncfile%%.*}.nc ../netcdf/${ncfile%%.*}.${PWD##*/}.nc # name will be, e.g., 4xdaily_inst.d0000-d0100.nc
  done
  echo "Time for combining files: $(($(date +%s) - $t))s."
  # Initialize directory for output
  ! [ -d ../netcdf ] && mkdir ../netcdf # make directory if doesn't exist
  ncfiles=(*.nc) # each output file
  # Remove some files
  [ -d INPUT ] && [ $cday -gt 0 ] && rm -rf INPUT # remove everything
  [ -r logfile.0000.out ] && mv logfile.0000.out log.init # contains init info
  rm fms.x # remove executable, because it takes up space
}

##############################################################################
# Run the model in blocks of $days days for control
##############################################################################
echo "Running control experiment from day $tstart to day $tend."
coldstart=true # assume cold start by default
origin=$(date +%s) # start time
pday=$(($tstart - $days)) # only time when we do minus days
cday=$tstart
nday=$(($tstart + $days))
while [ $nday -le $tend ]; do
  # Message and reset timer/flags
  echo "Running from day $cday to day $nday."
  time=$(date +%s)
  # Run the model and combine output
  # Optionally use the end of other control runs to reduce spinup time
  rdir=$expdir/d$(printf "%04d" $pday)-d$(printf "%04d" $cday)
  cdir=$expdir/d$(printf "%04d" $cday)-d$(printf "%04d" $nday)
  if ! [ -z $rinit ]; then coldstart=false
    if ! [[ $rinit =~ d.*-d.* ]]; then
      echo "Override: Using final day from \"$rinit\" for restart files."
      rinit=($rinit/d*-d*)
      rdir="${rinit[-1]}" # pick last one; the glob expansion will return a sorted list of names
    else
      echo "Override: Using restart files from \"$rinit\"."
      rdir="$rinit" # use specific day sequence
    fi
    unset rinit # only ever use this on first 'day' of a new experiment; for subsequent days, continue from earlier day block
    ! [ -d $rdir ] && raise "Override restart directory \"$rdir\" does not exist."
  fi
  dir_setup $cdir # sets up working directory, cd into it
  if [ $? -eq 0 ]; then # setup returns 1 if directory is present and 'resume' option is set
    if ! $coldstart || [ $cday -gt 0 ]; then
      copy_restart $rdir # put files into RESTART directory
    else
      echo "Cold start."
    fi
    run_model $rdir # run model
  fi
  # Step things forward, for next iteration
  pday=$cday
  cday=$(($pday + $days))
  nday=$(($cday + $days))
done
echo "The control run completed successfully in $(($(date +%s) - $origin)) seconds!"
echo "Timestamp: $(date)."
=======
# applying post-processing to a previous model step in the background, and organizing
# all the NetCDF files
################################################################################
run_model() {
  # Run model in parallel
  # Previously we set processor affinities
  local cday=$1 # the restart direcotry
  [ $# -ne 1 ] && raise "run_model() function takes exactly 1 argument."
  t1=$(date +%s)
  echo "Running model..."
  $run -np $cores ./fms.x &>log.model # need ./fms.x, not fms
  grep -E 'EXIT CODE: [1-9]|FATAL from PE|WARNING from PE' log.model &>/dev/null && \
    raise "Bad exit code from model run step."
  tmodel=$(cat log.model | grep "Total runtime*" | xargs | cut -d " " -f 5)
  echo "Model time: ${tmodel%.*}s." # is just max of the two

  # Remove some files
  [ -d INPUT ] && [ $cday -gt 0 ] && rm -rf INPUT # remove input *if* this is not start of new run; in that case we want to keep input so know what's going on
  [ -r logfile.0000.out ] && mv logfile.0000.out log.init # contains init info
  rm fms.x # remove executable, because takes up space

  # Process new data, and remove old data
  # Previously we set processor affinities, but didn't help much
  echo "Calling processing script with flags: $(echo $ipflags $pflags | xargs)"
  $process $ipflags $pflags &>log.process
  exit_check $?
  tprocess=$(tail -1 log.process | sed 's/[^0-9]*//g')
  echo "Process time: ${tprocess%.*}s."
}

################################################################################
# Run model for a second to get the *unchanging* forcing params, i.e. teq,
# kdamp, kfric, and ksponge.
# We output tdt, udt, vdt in full data files for convenience, but don't archive
# them; if you want to reconstruct them after-the-fact, just need these params.
################################################################################
# *First* check for input.nml existence
! [ -r $expdir/input.nml ]  && raise "input.nml file not found."
# Now make the forcing folder
echo "Generating forcing.nc file"
[ -d $expdir/forcing ] && rm -rf $expdir/forcing
mkdir $expdir/forcing # expdir was created several lines up
cd $expdir/forcing
mkdir RESTART # model spits out stuff here, can be accepted as input to new iteration
mkdir INPUT   # model reads from this
cp $expdir/input.nml ./ # identical namelist
sed -i 's/^.*[nr]damp_decomp.*$//g' input.nml # older runs had this option, now obsolete
nml_replace days 0 hours 0 minutes 0 seconds 1 dt_atmos 1
touch field_table # empty file for no tracers
cat > diag_table <<EOF
"Forcing scheme for dry core damping experiments."
0 0 0 0 0 0
# Filename
"forcing", 1, "seconds", 1, "days", "time",
# Parameters
"dynamics", "slp",        "slp",        "forcing", "all", .false., "none", 2,
"dynamics", "bk",         "hybi",       "forcing", "all", .false., "none", 2,
"dynamics", "pk",         "hyai",       "forcing", "all", .false., "none", 2,
"forcing",  "teq",        "teq",        "forcing", "all", .false., "none", 2,
"forcing",  "forcing",    "forcing",    "forcing", "all", .false., "none", 2,
"forcing",  "ndamp",      "ndamp",      "forcing", "all", .false., "none", 2,
"forcing",  "ndamp_mean", "ndamp_mean", "forcing", "all", .false., "none", 2,
"forcing",  "ndamp_anom", "ndamp_anom", "forcing", "all", .false., "none", 2,
"forcing",  "rdamp",      "rdamp",      "forcing", "all", .false., "none", 2,
"forcing",  "rdamp_mean", "rdamp_mean", "forcing", "all", .false., "none", 2,
"forcing",  "rdamp_anom", "rdamp_anom", "forcing", "all", .false., "none", 2,
EOF
# Quickly run model
cp $fms ./fms.x # move executable inside (declared at top of file)
$run -np 1 ./fms.x &>log.model # need ./fms.x, not fms
grep -E 'EXIT CODE: [1-9]|FATAL from PE|WARNING from PE' log.model &>/dev/null && \
  raise "Bad exit code from forcing run."
# Interpolate to pressure levels
# NOTE: We need surface pressure and temperature to interpolate from
# model half levels
ncrename -h -d pfull,mlev forcing.nc
ncrename -h -d phalf,ilev forcing.nc
ncrename -h -v pfull,mlev forcing.nc
ncrename -h -v phalf,ilev forcing.nc
ncatted -h -O -a bounds,mlev,o,c,"ilev" forcing.nc
[ -r ../forcing.nc ] && rm ../forcing.nc
ncl -n -Q 'filename="forcing.nc"' 'output="../forcing.nc"' $interp &>forcing.log
sed -i '/^.*warning:.*$/d;/^$/d' forcing.log
if ncl_check forcing.log || ! [ -r ../forcing.nc ]; then
  raise "Something failed during NCL interpolation of forcing data."
fi
# Exit if user *only* wanted to get initial conditions
$init && exit 0
# *Now* check for diag_table existence (not needed for forcing stuff)
! [ -r $expdir/diag_table ] && raise "diag_table file not found."

##############################################################################
# Control run
# Run the model in blocks of $days days for control, then optionally choose
# starting points from control for spin-down ensemble experiments
##############################################################################
estatus=0
case $mode in
  0) # Check that timing variables are declared
  # Prepare for the loop
  echo "Running control experiment from day $tstart to day $tend on $cores cores, restart every $days days."
  coldstart=true # assume cold start by default
  t0=$(date +%s) # start time
  pday=0 # only time when we do minus days
  cday=0
  nday=$days
  while [ $nday -le $tend ]; do
    # Message and reset timer/flagS
    # Skip this time (optionally)
    if [ $cday -lt $tstart ]; then
      unset rinit # important! for 'resume' experiments, generally just want to use rinit as cold start alternative
      pday=$cday # previous day
      cday=$((pday + days))
      nday=$((cday + days))
      continue
    fi
    echo "Running from day $cday to day $nday."
    time=$(date +%s)
    # Run the model and combine output
    # Optionally use the end of other control runs to reduce spinup time
    rdir=$expdir/d$(printf "%04d" $pday)-d$(printf "%04d" $cday)
    cdir=$expdir/d$(printf "%04d" $cday)-d$(printf "%04d" $nday)
    if [ -n "$rinit" ]; then
      coldstart=false
      echo "Override: Using restart files from \"$rinit\"."
      rdir="$rinit" # use specific day sequence
      unset rinit # only ever use this on first 'day' of a new experiment; for subsequent days, continue from earlier day block
      ! [ -d $rdir ] && raise "Override restart directory \"$rdir\" does not exist."
    fi
    unset ipflags
    array_in $cday ${t_nodata[@]} && ipflags+=" -q" && echo "Will delete output netcdf files."
    array_in $cday ${t_xyzdata[@]} && ipflags+=" -k" && echo "Will keep full res netcdf files."
    dir_setup $cday $cdir # sets up working directory, cd into it
    if [ $? -eq 0 ]; then # setup returns 1 if directory is present and 'resume' option is set
      if ! $coldstart || [ $cday -gt 0 ]; then
        copy_restart $cday $rdir # put files into RESTART directory
      else
        echo "Cold start."
      fi
      run_model $cday # run model
    fi
    [ $days -eq 0 ] && break # exit for initial condition experiment
    # Step things forward, for next iteration
    pday=$cday
    cday=$((pday + days))
    nday=$((cday + days))
  done
  # Last file
  echo "Processing last file..."
  wait $pp
  exit_check $?
  unset pp
  if [ -r log.process ]; then
    tprocess=$(tail -1 log.process | sed 's/[^0-9]*//g')
    echo "Final process time: ${tprocess%.*}s."
  fi
  # Message
  echo "The control run completed successfully in $(($(date +%s) - t0)) seconds!"
  echo "Timestamp: $(date)."

##############################################################################
# Spindown runs
# User must specify which namelist params are getting abruptly changed.
##############################################################################
  ;; *) # Check that timing variables are declared
  [ -z $t_spindown ] && raise "Must declare starting times for spindown experiments."
  # Prepare for the loop
  echo "Running spindown experiment $mode from days ${t_spindown[@]} for $tend days, restart every $days days."
  t0=$(date +%s)
  # Iterate through starting days
  for eday in "${t_spindown[@]}"; do
    cday=0 # current day relative to start of equilibrium
    nday=$days # next day, relative to start
    prefix=$expdir/d$(printf "%04d" $eday) # for successive spindown runs
    fstart=$expdir/d$(printf "%04d" $((eday - days)))-d$(printf "%04d" $eday) # for restart files from control
    ts=$(date +%s) # record time
    echo "Starting radiation-off spindown run from day $eday for $tend days."
    while [ $nday -le $tend ]; do
      # Skip this time (optionally)
      if [ $cday -lt $tstart ]; then
        echo "Skipping day $cday."
        pday=$cday # previous day
        cday=$((pday + days))
        nday=$((cday + days))
        continue
      fi
      # Get directories
      cdir=$prefix-spindown$mode-d$(printf "%04d" $cday)-d$(printf "%04d" $nday)
      [ $cday -eq 0 ] && rdir=$fstart || \
        rdir=$prefix-spindown$mode-d$(printf "%04d" $pday)-d$(printf "%04d" $cday)
      # Run the model and combine output
      unset ipflags
      array_in $cday ${t_nodata[@]} && ipflags+=" -q"
      array_in $cday ${t_xyznodata[@]} && ipflags+=" -k"
      dir_setup $cday $cdir # sets up working directory, cd into it
      if [ $? == 0 ]; then # returns 1 if we were requested not to overwrite old directories
        copy_restart $cday $rdir # add restart files
        run_model $cday # run model
      fi
      # Step things forward, for next iteration
      pday=$cday # previous day
      cday=$((pday + days))
      nday=$((cday + days))
    done
    echo "Spindown from $eday completed successfully in $(($(date +%s) - ts)) seconds!"
    echo "Timestamp: $(date)."
  done
  echo "Processing last file..."
  wait $pp
  exit_check $?
  unset pp
  if [ -r log.process ]; then
    tprocess=$(tail -1 log.process | sed 's/[^0-9]*//g')
    echo "Final process time: ${tprocess%.*}s."
  fi
  echo "The spindown runs completed successfuly in $(($(date +%s) - t0)) seconds!"
  echo "Timestamp: $(date)."

################################################################################
# Other experiments types can go below
################################################################################
  ;; *) raise "Unknown experiment type \"$mode\"." ;;
esac
>>>>>>> /home/ldavis/timescales-exps/drycore_run

